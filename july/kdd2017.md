# Finding Structures of Large Matrices Through Compression


learned:

- goal of paper: **scalable** low-rank approximation
- what low-rank approximation do
  - still a on-going topic
- application of low-rank: IR, RecSys, model compression (deep learning), etc
- prev state of the art based on randomized algorithm
  - memory consumption as bottle neck because it requires the whole matrix as input
- the paper goal: tackle the bottleneck using lossy data compression
  - achieves **linear** time and space


# *** Scalable and Sustainable Deep Learning via Randomized Hashing

- using locality sensitive hashing in training deep neural network

learned:

- dropout:
  - main idea: *randomly drop* units during *training* to prevent overfitting (a lot of parameters *co-adapting*)
- adaptive dropout: selectively drop units based on each unit's activation (gradient value?)
  - core question: identify the *sparse* set of neurons *efficiently*? 
  - this is what this paper studies (using locality sensitive hashing (LSH))
- LSH: maps similar points to the same hash value (bucket) with high probability
  - how to define "similarity" among neurons?
  - what's the hashing function?

- foreign language translation (google translate for image): also uses deep learning, maybe also easier than i thought (no image segmantation?)


# TrioVecEvent: Embedding-Based Online Local Event Detection in Geo-Tagged Tweet Streams

- geo-tagged "posts" (tweets, facebook, instagram, yelp, foursquare, etc)
  - location, time and text
- local event defined as: unsual busrty activity in a local region within short time and with a considerable amount of participants
- main idea: embed location, time and text into the same latent space
  - applicable in streaming case
  - claim to be efficient and accurate 

# Learning certifiably optimal rule lists for categorical data

- interesting point: interpretable and less interpretable classifiers with the same accuracy, how to find such interpretable classifiers?
- build decision rule list over *categorical* feature space
  - optimal and fast
- Q: how to define optimality?

# Clustering Individual Transactional Data for Masses of Users

- input: search engine queries, purchase records or clinical records
- why it's useful?
- what are the features? how to define similarity?

# *** Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks 

- [paper](http://www.cse.ust.hk/~qyaoaa/papers/kdd2017paper.pdf)
- collaborative filtering: matrix completion can be solved by low rank approximation
  - problem 1: cold start (no data for new users)
  - problem 2: sparsity
- meta-graph: seems to be dervied from meta-path (multiple meta graphs)
- *Q*: how is recommendation done exactly?
- meta graph selection using *group lasso*


# Effective and Real-time In-App Activity Analysis in Encrypted Internet Traffic Streams

- problem: classify user activity into different types from **encrypted** app-activity traffic
  - requirement: low memory and high accuracy

# FORA: Simple and Effective Approximate Single-Source Personalized PageRank

- problem: given a query, return the top-k results w.r.t personalized pagerank
- goal: do it efficiently

# A Minimal Variance Estimator for the Cardinality of Big Data Set Intersection

- problem: estimate size of intersection of set A and B
- idea: store **sketch** of the set and use **probabilistic estimator**
- application: 
  - optimizing join queries in dataset (A join B join C)
     - which two tables to join? (a join query simply performs set intersection)
  - document similarity based on set intersection
- further reading: sketch and estimation

# *** Online Ranking with Constraints: A Primal-Dual Algorithm and Applications to Web Traffic-Shaping

- online ranking with local objective (user engagement) and global constraint (num. of clicks/views)
- algorihtm based on linear programming duality 
- with **theoretical gaurantees**

# Internet Device Graphs

- built an internet device graph
- how to get the data
- what's an edge?


# Discrete Content-aware Matrix Factorization

- generate immediate recommendation (fast)
  - pre-computing does not capture user interest or item evolution
  - distributed computing is expensive
- adopts binary-code representation for matrix factorization problem (instead of real-valued)
  - saves memory (bool vs double)
  - hamming distance (XOR) is fast to compute
    - hamming dist: number of coordinates that are different
- however, a non-convex optimization problem
- should also handle implicit feedback

# The Selective Labels Problem: Evaluating Algorithmic Predictions in the Presence of Unobservables

- [link](https://cs.stanford.edu/people/jure/pubs/contraction-kdd17.pdf)
- selective labels problem: observed outcomes are themselves a consequence of the existing choices of the human decision-makers
- how to evaluate predictive models on selectively labeled data


# Long Short Memory Process: Modeling Growth Dynamics of Microscopic Social Connectivity

- [paper](http://media.cs.tsinghua.edu.cn/~multimedia/cuipeng/papers/MicroSocialDynamics.pdf)
- modeling how number of friends evolves over time

# Ego-splitting Framework: from Non-Overlapping to Overlapping Cluster

- [paper](http://renatoppl.com/papers/egonet.pdf)
- detecting overlapping clusters via ego-networks
- via a reduction to non-overalapping clustering problem
- use the guidance of local clustering structure to detect overlapping communities. (idea not new)
- innovation: scalability

learned:

- lack of macroscopic community structure in real world networks (same feeling).
- community is simple at a microscopic level -- ego networks (family, collegues, classmates, etc)
- google has graph research team and NYC

# *** AnnexML: Approximate Nearest Neighbor Search for Extreme Multi-label Classification

- nextreme multi-label classification using graph embedding and approx nearest neighbor search
- using matrix factorization

# Collaboratively Improving Topic Discovery and Word Embeddings by Coordinating Global and Local Contexts

- topic modeling (global) + word embedding (local)
- what's the obj function?

video tool: powtoon


# Graph Edge Partitioning via Neighborhood Heuristic

- what's edge cut?
  - cut vertices to split edges into clusters
- why edge cut?
  - easier to product balanced and small cut (because nodes' degree follow power-law in practice)

# An Online Hierarchical Algorithm for Extreme Clustering

- extreme clustering -- very large k (\# of clusters)
- demonstrated in real world
  - record (document for example) de-duplication
  - entity resolution
  - clustering ImageNet images (many labels)
- online
- hierarchical (why?)

# Is the Whole Greater Than the Sum of Its Parts?

predict the outcome (performance) of the whole and parts

a related question, how to maximize the outcome by changing the system?

# Tracking the Dynamics in Crowdfunding

forecast the funding amount

background:

- backer: a person, institution, or country that supports something, especially financially.
- equity: the value of the shares issued by a company.
- compaign: a activitiy set by the creator to raise money
- perk: different amount of money a backer can give while receiving different amounts of rewards

input:

- funding sequence and feature of compaign and perks, 
- funding amount on the next days


# *** Weisfeiler-Lehman Neural Machine for Link Prediction

deep learning for link prediction

- data generation (DL needs a lot of data, mentioned by Feifei Li)
  - use the surrounding subgraph for each link
- encoding subgraph to vector?
  - graph labeling to determine vertex order
  - then construct adj matrix
  - **novelty**: a fast hashing-based Weisfeiler-Lehman (WL) algorithm that labels the vertices according to their structural roles
- no embedding is used

# A Local Algorithm for Structure-Preserving Graph Cut

certain structures are intersting such as triangle, loop 

we do not want to lose them when cutting a graph.

this paper studies how to do graph cut while preserving interesting structures.



