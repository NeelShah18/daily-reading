# Finding Structures of Large Matrices Through Compression


learned:

- goal of paper: **scalable** low-rank approximation
- what low-rank approximation do
  - still a on-going topic
- application of low-rank: IR, RecSys, model compression (deep learning), etc
- prev state of the art based on randomized algorithm
  - memory consumption as bottle neck because it requires the whole matrix as input
- the paper goal: tackle the bottleneck using lossy data compression
  - achieves **linear** time and space


# *** Scalable and Sustainable Deep Learning via Randomized Hashing

- using locality sensitive hashing in training deep neural network

learned:

- dropout:
  - main idea: *randomly drop* units during *training* to prevent overfitting (a lot of parameters *co-adapting*)
- adaptive dropout: selectively drop units based on each unit's activation (gradient value?)
  - core question: identify the *sparse* set of neurons *efficiently*? 
  - this is what this paper studies (using locality sensitive hashing (LSH))
- LSH: maps similar points to the same hash value (bucket) with high probability
  - how to define "similarity" among neurons?
  - what's the hashing function?

- foreign language translation (google translate for image): also uses deep learning, maybe also easier than i thought (no image segmantation?)


# *** TrioVecEvent: Embedding-Based Online Local Event Detection in Geo-Tagged Tweet Streams

- geo-tagged "posts" (tweets, facebook, instagram, yelp, foursquare, etc)
  - location, time and text
- local event defined as: unsual busrty activity in a local region within short time and with a considerable amount of participants
- main idea: embed location, time and text into the same latent space
  - applicable in streaming case
  - claim to be efficient and accurate 

# Learning certifiably optimal rule lists for categorical data

- interesting point: interpretable and less interpretable classifiers with the same accuracy, how to find such interpretable classifiers?
- build decision rule list over *categorical* feature space
  - optimal and fast
- Q: how to define optimality?

# Clustering Individual Transactional Data for Masses of Users

- input: search engine queries, purchase records or clinical records
- why it's useful?
- what are the features? how to define similarity?

# *** Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks 

- [paper](http://www.cse.ust.hk/~qyaoaa/papers/kdd2017paper.pdf)
- collaborative filtering: matrix completion can be solved by low rank approximation
  - problem 1: cold start (no data for new users)
  - problem 2: sparsity
- meta-graph: seems to be dervied from meta-path (multiple meta graphs)
- *Q*: how is recommendation done exactly?
- meta graph selection using *group lasso*


# Effective and Real-time In-App Activity Analysis in Encrypted Internet Traffic Streams

- problem: classify user activity into different types from **encrypted** app-activity traffic
  - requirement: low memory and high accuracy

# FORA: Simple and Effective Approximate Single-Source Personalized PageRank

- problem: given a query, return the top-k results w.r.t personalized pagerank
- goal: do it efficiently

# A Minimal Variance Estimator for the Cardinality of Big Data Set Intersection

- problem: estimate size of intersection of set A and B
- idea: store **sketch** of the set and use **probabilistic estimator**
- application: 
  - optimizing join queries in dataset (A join B join C)
     - which two tables to join? (a join query simply performs set intersection)
  - document similarity based on set intersection
- further reading: sketch and estimation

# *** Online Ranking with Constraints: A Primal-Dual Algorithm and Applications to Web Traffic-Shaping

- online ranking with local objective (user engagement) and global constraint (num. of clicks/views)
- algorihtm based on linear programming duality 
- with **theoretical gaurantees**

# Internet Device Graphs

- built an internet device graph
- how to get the data
- what's an edge?


# Discrete Content-aware Matrix Factorization

- generate immediate recommendation (fast)
  - pre-computing does not capture user interest or item evolution
  - distributed computing is expensive
- adopts binary-code representation for matrix factorization problem (instead of real-valued)
  - saves memory (bool vs double)
  - hamming distance (XOR) is fast to compute
    - hamming dist: number of coordinates that are different
- however, a non-convex optimization problem
- should also handle implicit feedback

# The Selective Labels Problem: Evaluating Algorithmic Predictions in the Presence of Unobservables

- [link](https://cs.stanford.edu/people/jure/pubs/contraction-kdd17.pdf)
- selective labels problem: observed outcomes are themselves a consequence of the existing choices of the human decision-makers
- how to evaluate predictive models on selectively labeled data


# Long Short Memory Process: Modeling Growth Dynamics of Microscopic Social Connectivity

- [paper](http://media.cs.tsinghua.edu.cn/~multimedia/cuipeng/papers/MicroSocialDynamics.pdf)
- modeling how number of friends evolves over time

# Ego-splitting Framework: from Non-Overlapping to Overlapping Cluster

- [paper](http://renatoppl.com/papers/egonet.pdf)
- detecting overlapping clusters via ego-networks
- via a reduction to non-overalapping clustering problem
- use the guidance of local clustering structure to detect overlapping communities. (idea not new)
- innovation: scalability

learned:

- lack of macroscopic community structure in real world networks (same feeling).
- community is simple at a microscopic level -- ego networks (family, collegues, classmates, etc)
- google has graph research team and NYC

# *** AnnexML: Approximate Nearest Neighbor Search for Extreme Multi-label Classification

- nextreme multi-label classification using graph embedding and approx nearest neighbor search
- using matrix factorization

# Collaboratively Improving Topic Discovery and Word Embeddings by Coordinating Global and Local Contexts

- topic modeling (global) + word embedding (local)
- what's the obj function?

video tool: powtoon


# Graph Edge Partitioning via Neighborhood Heuristic

- what's edge cut?
  - cut vertices to split edges into clusters
- why edge cut?
  - easier to product balanced and small cut (because nodes' degree follow power-law in practice)

# An Online Hierarchical Algorithm for Extreme Clustering

- extreme clustering -- very large k (\# of clusters)
- demonstrated in real world
  - record (document for example) de-duplication
  - entity resolution
  - clustering ImageNet images (many labels)
- online
- hierarchical (why?)

# Is the Whole Greater Than the Sum of Its Parts?

predict the outcome (performance) of the whole and parts

a related question, how to maximize the outcome by changing the system?

# Tracking the Dynamics in Crowdfunding

forecast the funding amount

background:

- backer: a person, institution, or country that supports something, especially financially.
- equity: the value of the shares issued by a company.
- compaign: a activitiy set by the creator to raise money
- perk: different amount of money a backer can give while receiving different amounts of rewards

input:

- funding sequence and feature of compaign and perks, 
- funding amount on the next days


# *** Weisfeiler-Lehman Neural Machine for Link Prediction

deep learning for link prediction

- data generation (DL needs a lot of data, mentioned by Feifei Li)
  - use the surrounding subgraph for each link
- encoding subgraph to vector?
  - graph labeling to determine vertex order
  - then construct adj matrix
  - **novelty**: a fast hashing-based Weisfeiler-Lehman (WL) algorithm that labels the vertices according to their structural roles
- no embedding is used

# A Local Algorithm for Structure-Preserving Graph Cut

certain structures are intersting such as triangle, loop 

we do not want to lose them when cutting a graph.

this paper studies how to do graph cut while preserving interesting structures.


# Structural Deep Brain Network Mining

embedding for brain network

1. reorder/label the nodes (clustering)
2. enhance it
3. autoencoder and cnn to derive the embedding (for classification purpose)

# struc2vec: Learning Node Representations from Structural Identity

structural identity -- roles in a social network, functions in a protein network (thought they might be very far from each other in the network)

(might use node label or edge label information)

if such info is absent, can we leverage structural information?

- for example two nodes are similar if they have similar degree and connected to the similar amount of triangles
  - however, they might be far from each other in the network (w.r.t path length)
- network might have disconnected components

learned:

- using label/tag to define proximity
- multiple auto-encoders for different types of neighbors (for example, for a post, two encoders for tags and likers respectively)

# *** PReP: Path-Based Relevance from a Probabilistic Perspective in Heteogeneous Information Networks

- [paper](https://arxiv.org/abs/1706.01177)
- a generalization for many relevance measures such as [PathSim](http://www.vldb.org/pvldb/vol4/p992-sun.pdf)
- tailored for each dataset
- only evaluated on two datasets

# The Co-Evolution Model for Social Network Evolving and Opinion Migration

- observation: network structure and node opinion **co-evolves** (such as US politics)

two models:

- network generative model when node property (topic vector) is known
- a property migration model when structure is known
- used for prediction of structure or property

# On Finding Socially Tenuous Groups for Online Social Networks

finding groups of nodes so that in the group:

- people do not know each other (to avoid embarassment)

# Detecting Network Effects: Randomizing Over Randomized Experiments

- A/B test: usually testing new features of online platforms by randomly serving users with two versions of the same service (treatment and control)
- assumption by A/B testing -- stable treatment value assumption. treatment effect does not spill over friends
- goal: measuring whether treatment effect spills over friendship network

# Visualizing Attributed Graphs via Terrain Metaphor

- visualize a graph with real-valued attributes into a 3D terrain metaphor
- attributes might be: k-core number, centrality, etc
- 3D and interactive (scalable)
- facilitates tasks:
  - find densest k-core in the graph
  - what about other measures?

# Inferring the strength of social ties: a community-driven approach

strong triadic closure: two strong friends of yours must be at least weak friends

- input: graph and sets of communities
- output: edge labels as strong/weak
- s.t.:
  - community node are connected by strong ties
  - number of violated triangles is minimized

# *** Structural Diversity and Homophily: A Study Across More Than One Hundred Big Networks

- testing whether principle of homophily holds
- homophily principle: people with more common friends are more likely to form a link with each other
  - not always true
- the paper studies the impact of the common neighborhood diversity on link existence can **vary substantially** across networks
  - in some cases, fewer mutual connections may lead to higher tendency to link with each other (like marriage among my friends)
  - one question: why results differ?
- a study over 120 networks
- pointing to potential advancement in designing random graph models and recommender systems.

# Learning from Multiple Teacher Networks

- goal of student-teacher learning paradigm: train thin but deep network (reduce paremter size and increase excution speed)

# *** GRAM: Graph-based Attention Model for Healthcare Representation Learning

deep learning challenges in health-care:

- data insufficiency
- interpretability

approach: using representation learning to supplement other tasks

input:

medical ontology: a DAG
  - node as concept
  - edge as relation 
  - from general to specific
  - example: disease

output: embedding via attention mechanism

# When is a Network a Network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks

[paper](https://arxiv.org/pdf/1702.05499.pdf)

# Learning from Labeled and Unlabeled Vertices in Networks

- semi-supervied learning on graph    

# Relay-Linking Models for Prominence and Obsolescence in Evolving Networks

[paper](https://pdfs.semanticscholar.org/f536/1709fe2ce7a372565cd9fc942e0cd12769d0.pdf)

- models the rate at which nodes acquire links in an evolving social network
- entrenchment vs obsolescence over time
  - entrechment: "rich-gets-richer"
- existing method: per node parameter: huge
- proposes temporal sketch of an evolving graph


# 