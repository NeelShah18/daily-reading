# kim cnn

- https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras
- https://gist.github.com/entron/b9bc61a74e7cadeb1fec
- https://github.com/harsh19/CNN-Text-Classification
- https://github.com/deepanwayx/CNN-For-Sentence-Classification-In-Keras/blob/master/trainGraph.py

# autoencoder

- https://blog.keras.io/building-autoencoders-in-keras.html

alternative problem: representation learning by reconstructing from jigsaw puzzle (instead of pixel-level details)
- [paper](https://arxiv.org/abs/1603.09246)

## application

- found application in train deep NN, 2012
- replaced by better weight initialization
- batch normalization, 2014
- residual learning, 2015

- dimension reduction for visualization
  - t-SNE requires relative low dimensional data
- **data denoising**

## instances

- shallow encoder/decoder
- deep encoder/decoder
- cnn-based
- denoising example
- sequence to sequence