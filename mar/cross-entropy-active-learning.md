
# Cross-Entropy as a Criterion for Robust Interactive Learning of Latent Properties

# minimum expected

reduce the entropy on hidden variables

essentially our prederror method

underlying assumption: our model is more or less correct

# maximum cross entropy

maximally confront the current belief

the different is interesting, just reversing the position of the pior and posterior belief (Equation 1 and 4)

underlying assumption: our model can be "very" wrong

# links

http://www.filmnips.com/wp-content/uploads/2016/11/FILM-NIPS2016_paper_23.pdf